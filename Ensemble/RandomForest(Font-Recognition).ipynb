{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F0', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'F11', 'F12', 'F13']\n"
     ]
    }
   ],
   "source": [
    "x_cols = []\n",
    "for i in range(14):\n",
    "    x_cols.append('F' + str(i))\n",
    "print(x_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "y_cols = list(string.ascii_uppercase)\n",
    "print(y_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"MultiFontCharInput.csv\", names=x_cols, header=None)\n",
    "x_test = pd.read_csv(\"MultiFontCharInputTestData.csv\", names=x_cols, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\"MultiFontCharOutput.csv\", names=y_cols, header=None)\n",
    "y_test = pd.read_csv(\"MultiFontCharOutputTestData.csv\", names=y_cols, header=None)\n",
    "y_cattr = y_train.apply(lambda x: x.idxmax(), axis = 1)\n",
    "y_catte = y_test.apply(lambda x: x.idxmax(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier( n_estimators=50,random_state=33)\n",
    "clf = clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.769 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "def measure_performance(X,y,clf, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "    y_pred=clf.predict(X)   \n",
    "    if show_accuracy:\n",
    "        print (\"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y,y_pred)),\"\\n\")\n",
    "\n",
    "    if show_classification_report:\n",
    "        print (\"Classification report\")\n",
    "        print (metrics.classification_report(y,y_pred),\"\\n\")\n",
    "        \n",
    "    if show_confusion_matrix:\n",
    "        print (\"Confusion matrix\")\n",
    "        print (metrics.confusion_matrix(y,y_pred),\"\\n\")\n",
    "        \n",
    "measure_performance(x_test,y_test,clf, show_classification_report=False, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from scipy.stats import sem\n",
    "\n",
    "def loo_cv(X_train,y_train,clf):\n",
    "    # Perform Leave-One-Out cross validation\n",
    "    # We are preforming 1313 classifications!\n",
    "    loo = LeaveOneOut()\n",
    "    scores=np.zeros(X_train[:].shape[0])\n",
    "    for train_index,test_index in loo.split(X_train):\n",
    "        X_train_cv, X_test_cv= X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_cv, y_test_cv= y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        clf = clf.fit(X_train_cv,y_train_cv)\n",
    "        y_pred=clf.predict(X_test_cv)\n",
    "        scores[test_index]=metrics.accuracy_score(y_test_cv.astype(int), y_pred.astype(int))\n",
    "    print ((\"Mean score: {0:.3f} (+/-{1:.3f})\").format(np.mean(scores), sem(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 0.808 (+/-0.032)\n"
     ]
    }
   ],
   "source": [
    "x_data = x_train.append(x_test, ignore_index=True)\n",
    "y_data = y_train.append(y_test, ignore_index=True)\n",
    "loo_cv (x_data, y_data, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(x_data, y_data, test_size=0.20, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.781 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         0\n",
      "          2       1.00      0.50      0.67         2\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      1.00      1.00         3\n",
      "          5       1.00      1.00      1.00         2\n",
      "          6       1.00      1.00      1.00         1\n",
      "          7       0.00      0.00      0.00         0\n",
      "          8       0.67      1.00      0.80         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       1.00      1.00      1.00         1\n",
      "         11       1.00      1.00      1.00         1\n",
      "         12       1.00      1.00      1.00         1\n",
      "         13       0.00      0.00      0.00         0\n",
      "         14       0.00      0.00      0.00         0\n",
      "         15       0.00      0.00      0.00         0\n",
      "         16       1.00      0.50      0.67         2\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         1\n",
      "         19       0.00      0.00      0.00         0\n",
      "         20       1.00      1.00      1.00         1\n",
      "         21       1.00      0.33      0.50         3\n",
      "         22       1.00      1.00      1.00         1\n",
      "         23       1.00      0.50      0.67         2\n",
      "         24       1.00      0.50      0.67         2\n",
      "         25       1.00      1.00      1.00         2\n",
      "\n",
      "avg / total       0.98      0.78      0.84        32\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = clf.fit(x_tr,y_tr)\n",
    "measure_performance(x_te,y_te,clf, show_classification_report=True, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
