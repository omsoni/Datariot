{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F0', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'F11', 'F12', 'F13']\n"
     ]
    }
   ],
   "source": [
    "x_cols = []\n",
    "for i in range(14):\n",
    "    x_cols.append('F' + str(i))\n",
    "print(x_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"MultiFontCharInput.csv\", names=x_cols, header=None)\n",
    "x_test = pd.read_csv(\"MultiFontCharInputTestData.csv\", names=x_cols, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "y_cols = list(string.ascii_uppercase)\n",
    "print(y_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\"MultiFontCharOutput.csv\", names=y_cols, header=None)\n",
    "y_test = pd.read_csv(\"MultiFontCharOutputTestData.csv\", names=y_cols, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=20 ,min_samples_leaf=3)\n",
    "clf = clf.fit(x_train,y_train)\n",
    "dp = clf.decision_path(x_train)\n",
    "#print(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdata = tree.export_graphviz(clf, out_file=\"dt.png\", filled=True, rounded=True)\n",
    "graph = graphviz.Source(gdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.718 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      1.00      0.75         3\n",
      "          1       0.75      1.00      0.86         3\n",
      "          2       0.50      0.67      0.57         3\n",
      "          3       0.25      0.33      0.29         3\n",
      "          4       1.00      0.67      0.80         3\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       0.00      0.00      0.00         3\n",
      "          7       1.00      1.00      1.00         3\n",
      "          8       0.75      1.00      0.86         3\n",
      "          9       0.33      0.33      0.33         3\n",
      "         10       1.00      0.67      0.80         3\n",
      "         11       1.00      0.67      0.80         3\n",
      "         12       0.75      1.00      0.86         3\n",
      "         13       1.00      1.00      1.00         3\n",
      "         14       0.60      1.00      0.75         3\n",
      "         15       0.67      0.67      0.67         3\n",
      "         16       1.00      0.67      0.80         3\n",
      "         17       0.25      0.33      0.29         3\n",
      "         18       1.00      0.67      0.80         3\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       1.00      0.67      0.80         3\n",
      "         21       1.00      0.67      0.80         3\n",
      "         22       0.00      0.00      0.00         3\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       0.43      1.00      0.60         3\n",
      "         25       1.00      0.67      0.80         3\n",
      "\n",
      "avg / total       0.73      0.72      0.70        78\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omsoni/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1139: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "def measure_performance(X,y,clf, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "    y_pred=clf.predict(X)   \n",
    "    if show_accuracy:\n",
    "        print (\"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y,y_pred)),\"\\n\")\n",
    "\n",
    "    if show_classification_report:\n",
    "        print (\"Classification report\")\n",
    "        print (metrics.classification_report(y,y_pred),\"\\n\")\n",
    "        \n",
    "    if show_confusion_matrix:\n",
    "        print (\"Confusion matrix\")\n",
    "        print (metrics.confusion_matrix(y,y_pred),\"\\n\")\n",
    "        \n",
    "measure_performance(x_test,y_test,clf, show_classification_report=True, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from scipy.stats import sem\n",
    "\n",
    "def loo_cv(X_train,y_train,clf):\n",
    "    # Perform Leave-One-Out cross validation\n",
    "    # We are preforming 1313 classifications!\n",
    "    loo = LeaveOneOut()\n",
    "    scores=np.zeros(X_train[:].shape[0])\n",
    "    for train_index,test_index in loo.split(X_train):\n",
    "        X_train_cv, X_test_cv= X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_cv, y_test_cv= y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        clf = clf.fit(X_train_cv,y_train_cv)\n",
    "        y_pred=clf.predict(X_test_cv)\n",
    "        scores[test_index]=metrics.accuracy_score(y_test_cv.astype(int), y_pred.astype(int))\n",
    "    print ((\"Mean score: {0:.3f} (+/-{1:.3f})\").format(np.mean(scores), sem(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 0.808 (+/-0.032)\n"
     ]
    }
   ],
   "source": [
    "x_data = x_train.append(x_test, ignore_index=True)\n",
    "y_data = y_train.append(y_test, ignore_index=True)\n",
    "loo_cv (x_data, y_data, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A', 0.28841504978004556)\n",
      "('B', 0.1490237067841796)\n",
      "('C', 0.1680994927103273)\n",
      "('D', 0.08656464120637661)\n",
      "('E', 0.0)\n",
      "('F', 0.1627906040730638)\n",
      "('G', 0.025529237127498997)\n",
      "('H', 0.02878773295460032)\n",
      "('I', 0.05444562672883674)\n",
      "('J', 0.0)\n",
      "('K', 0.0)\n",
      "('L', 0.017127128192529054)\n",
      "('M', 0.019216780442542054)\n",
      "('N', 0.0)\n"
     ]
    }
   ],
   "source": [
    "for feature in zip(y_cols, clf.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(x_data, y_data, test_size=0.40, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.730 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       1.00      1.00      1.00         1\n",
      "          2       0.43      1.00      0.60         3\n",
      "          3       1.00      0.33      0.50         3\n",
      "          4       1.00      1.00      1.00         3\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      0.67      0.80         3\n",
      "          7       0.67      1.00      0.80         2\n",
      "          8       0.75      1.00      0.86         3\n",
      "          9       0.40      0.67      0.50         3\n",
      "         10       1.00      1.00      1.00         1\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         1\n",
      "         13       0.67      1.00      0.80         2\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.50      1.00      0.67         2\n",
      "         16       0.00      0.00      0.00         4\n",
      "         17       1.00      1.00      1.00         2\n",
      "         18       1.00      1.00      1.00         3\n",
      "         19       1.00      1.00      1.00         2\n",
      "         20       0.50      1.00      0.67         1\n",
      "         21       0.00      0.00      0.00         4\n",
      "         22       0.00      0.00      0.00         2\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       0.50      0.67      0.57         3\n",
      "         25       1.00      1.00      1.00         4\n",
      "\n",
      "avg / total       0.67      0.73      0.68        63\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omsoni/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1139: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf = clf.fit(x_tr,y_tr)\n",
    "measure_performance(x_te,y_te,clf, show_classification_report=True, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
